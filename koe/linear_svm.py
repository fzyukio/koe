import numpy as np
import tensorflow as tf

# Global variables.
import time

BATCH_SIZE = 100  # The number of training examples to use per training step.

# # Define the flags useable from the command line.
# tf.app.flags.DEFINE_string('train', None,
#                            'File containing the training data (labels & features).')
# tf.app.flags.DEFINE_integer('num_epochs', 1,
#                             'Number of training epochs.')
# tf.app.flags.DEFINE_float('svmC', 1,
#                           'The C parameter of the SVM cost function.')
# tf.app.flags.DEFINE_boolean('verbose', False, 'Produce verbose output.')
# tf.app.flags.DEFINE_boolean('plot', True, 'Plot the final decision boundary on the data.')
# FLAGS = tf.app.flags.FLAGS


# Extract numpy representations of the labels and features given rows consisting of:
#   label, feat_0, feat_1, ..., feat_n
#   The given file should be a comma-separated-values (CSV) file saved by the savetxt command.
def extract_data(filename):
    out = np.loadtxt(filename, delimiter=',')

    # Arrays to hold the labels and feature vectors.
    labels = out[:, 0]
    labels = labels.reshape(labels.size, 1)
    fvecs = out[:, 1:]

    # Return a pair of the feature matrix and the one-hot label matrix.
    return fvecs, labels


def main():
    # Be verbose?
    verbose = False

    # Get the data.
    train_data_filename = 'linearly_separable_data.csv'

    # Extract it into numpy matrices.
    train_data, train_labels = extract_data(train_data_filename)

    # Convert labels to +1,-1
    train_labels[train_labels == 0] = -1

    # Get the shape of the training data.
    train_size, num_features = train_data.shape

    # Get the number of epochs for training.
    num_epochs = 1000

    # Get the C param of SVM
    svmC = 1

    # This is where training samples and labels are fed to the graph.
    # These placeholder nodes will be fed a batch of training data at each
    # training step using the {feed_dict} argument to the Run() call below.
    x = tf.placeholder("float", shape=[None, num_features])
    y = tf.placeholder("float", shape=[None, 1])

    # Define and initialize the network.

    # These are the weights that inform how much each feature contributes to
    # the classification.
    W = tf.Variable(tf.zeros([num_features, 1]))
    b = tf.Variable(tf.zeros([1]))
    y_raw = tf.matmul(x, W) + b

    # Optimization.
    regularization_loss = 0.5 * tf.reduce_sum(tf.square(W))
    hinge_loss = tf.reduce_sum(tf.maximum(tf.zeros([BATCH_SIZE, 1]),
                                          1 - y * y_raw));
    svm_loss = regularization_loss + svmC * hinge_loss;
    train_step = tf.train.GradientDescentOptimizer(0.01).minimize(svm_loss)

    # Evaluation.
    predicted_class = tf.sign(y_raw);
    correct_prediction = tf.equal(y, predicted_class)
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))

    # Create a local session to run this computation.
    with tf.Session() as s:
        # Run all the initializers to prepare the trainable parameters.
        tf.initialize_all_variables().run()
        if verbose:
            print('Initialized!')
            print()
            print('Training.')

        # Iterate and train.
        for step in range(num_epochs * train_size // BATCH_SIZE):
            if verbose:
                print(step, end=' ')

            offset = (step * BATCH_SIZE) % train_size
            batch_data = train_data[offset:(offset + BATCH_SIZE), :]
            batch_labels = train_labels[offset:(offset + BATCH_SIZE)]
            train_step.run(feed_dict={x: batch_data, y: batch_labels})
            # print('loss: ', svm_loss.eval(feed_dict={x: batch_data, y: batch_labels}))

            if verbose and offset >= train_size - BATCH_SIZE:
                print()

        # Give very detailed output.
        if verbose:
            print()
            print('Weight matrix.')
            print(s.run(W))
            print()
            print('Bias vector.')
            print(s.run(b))
            print()
            print("Applying model to first test instance.")
            print()

        print("Accuracy on train:", accuracy.eval(feed_dict={x: train_data, y: train_labels}))


if __name__ == '__main__':
    start = time.time()
    main()
    elapsed = time.time() - start
    print('Elapsed time = {}'.format(elapsed))
