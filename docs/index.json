[
{
	"uri": "http://koe-wiki.github.io/features/time-domain/",
	"title": "Frequency domain features",
	"tags": [],
	"description": "",
	"content": "Spectral Flux Is the measure of the changes in the shape of the spectrum over time. SF is computed as the Euclidean ($L^2$) distance of two consecutive spectral frames with normalised PSD\nSpectral Slope For many natural audio signals, the energy of the spectrum tends to decrease towards the higher end of the frequency range, the \u0026ldquo;slope\u0026rdquo; of which is related to the nature of the sound source. This parameter can be found via linear regression of the magnitude: $$x(f) = slope \\times f + intercept$$ where $x(f)$ is the magnitude function and $f$ is the frequency value. In addition to slope, the intercept and regression error can also be used as features.\nSpectral Centroid is the centre of gravity of the spectrum, calculated as the weighted mean of the frequencies using their normalised magnitude as weights:\n$$SC = \\sum_{n=1}^{N} \\Big(f(n) \\times x(n)\\Big) \\Bigg/ \\sum_{n=1}^{N} x(n)$$\nWhere $N$ is the total number of frequency bins, $a(n)$ is the normalised magnitude of the spectrum at bin $n$ and $f(n)$ is the centre frequency of bin $n$. Value of SC is the frequency where most of the energy is concentrated in, which is usually where the dominant frequency is found.\nSpectral Centre Is the frequency where half of the energy in the magnitude spectrum is above and half is below\nSpectral Rolloff Is defined as the \\textit{N}% percentile of the power spectrum. In practice, the value of \\textit{N} is usually at the higher end (85, 95, etc).\nSpectral Centre is a Spectral Rolloff with $N=50$\nSpectral Flatness Also known as Wiener entropy is a measure of the noisiness of the spectrum, of which the higher value correspond to a more uniform distribution of power over all frequencies. It is computed as the ratio of the geometric mean over the arithmetic mean of the spectrum:\n$$SF = \\sqrt[N]{\\prod_{n=1}^{N}x(n)} \\Bigg/% \\frac{1}{N} \\sum_{n=1}^{N}x(n)$$\nSpectral Crest Is the opposite of Spectral Flatness. it measures how peaky the spectrum is. A noisy spectrum have low value of SCF compare to a clear tonal spectrum. It is calculated as the ratio of the peak over the mean frequency value:\n\\begin{equation*} SCF = \\max_{1 \\le n \\le N} x(n) \\Bigg/ \\frac{1}{N} \\sum_{n=1}^{N}x(n) \\end{equation*}\nBandwidth Also known as Spectral Spread, is usually defined as the magnitude-weighted average of the differences between the spectral components and the spectral centroid\n\\begin{equation*} BW = \\sum_{n=1}^{N} \\Big(\\big(f(n)-SC\\big) \\times x(n)\\Big) \\Bigg/ \\sum_{n=1}^{N} x(n) \\label{eq:bandwidth} \\end{equation*}\nFundamental Frequency Is the lowest frequency of a harmonic series. It concurs with the rate of oscillation of the sound source. The FF is the same as the dominant frequency in case of pure-tone signals, which makes it relatively straightforward to determine. However, this is not the case with speech and many bird\u0026rsquo;s vocalisations, which produce complex sound (having harmonic structure). The fundamental frequency of a harmonic series can be determined as either the lowest harmonic or more reliably (in the case of missing fundamental) by finding the largest common denominator of the harmonics.\nHarmonic Ratio Is the ratio of harmonic power to total power, it is computed in the autocorrelation domain and defined as the maximum value of the normalised autocorrelation function (after having ignored the zero-lag peak) within a frame of length $k$:\n\\begin{equation*} HR = \\max_k \\Bigg(\\sum\\nolimits_j \\Big(s(j)\\times s(j-k)\\Big) \\Big/ \\sqrt{\\sum\\nolimits_j s(j)^2 \\sum\\nolimits_j s(j-k)^2} \\Bigg) \\end{equation*}\nWhere $s(j)$ is the function of sound pressure in time domain.\n"
},
{
	"uri": "http://koe-wiki.github.io/user-manual/",
	"title": "User&#39;s Manual",
	"tags": [],
	"description": "",
	"content": "Koe features tools for visualising, segmenting, measuring, classifying, data-filtering and exporting acoustic units, and analysing sequence structure (syntax). It is an end-to-end acoustic database solution, especially suitable for animal species with distinct acoustic units.\nYou can use it on any device at koe.io.ac.nz, which makes it ideal for collaboration, education, and citizen science.\nFor a quick overview and demonstration of program features, see this video:\n  Table of content \rWhy use Koe?\r\r\r\r\rOverview of Koe workflow\r\r\r\r\rNavigating Koe\r\r\r\r\rUser and database control\r\r\r\r\rSongs control\r\r\r\r\r"
},
{
	"uri": "http://koe-wiki.github.io/",
	"title": "Welcome to Koe&#39;s Wiki",
	"tags": [],
	"description": "",
	"content": "Koe Wiki Koe is open-source web-based software for analysing animal vocalisations.\nRead the Methods in Ecology and Evolution paper here. Please cite this paper if you publish using Koe\nTable of content \rUser\u0026#39;s Manual\r\r\r\rWhy use Koe?\r\r\r\r\rOverview of Koe workflow\r\r\r\r\rNavigating Koe\r\r\r\r\rUser and database control\r\r\r\r\rSongs control\r\r\r\r\r\rAcoustic features\r\r\r\rFrequency domain features\r\r\r\r\rTime domain features\r\r\r\r\rPerceptual based features\r\r\r\r\r\r"
},
{
	"uri": "http://koe-wiki.github.io/user-manual/why-use-koe/",
	"title": "Why use Koe?",
	"tags": [],
	"description": "",
	"content": "Acoustic communication is fundamental to the behaviour of many species. If we want to understand animal behaviour we need tools that allow us to objectively examine the details of vocalisations. What information are they sharing, and how is it encoded?\nOften, acoustic communication is structured as a temporal sequence of distinct acoustic units (e.g. syllables), where information is encoded in the types of units and sometimes their temporal arrangement (syntax). In such cases, this is the flowchart for acoustic analysis:\nClassification is a key step, because once you have a dataset of labelled units, you can analyse repertoire size and sequence structure and compare between individuals, sexes, sites, and seasons.\nManual classification by human eye and ear remains the primary and most reliable method for most species, but is hindered by a lack of tools, especially for large and diverse datasets.\nThat’s where Koe comes in. By facilitating large-scale, high-resolution classification and analysis of acoustic units, Koe opens up many possibilities for bioacoustics research.\n"
},
{
	"uri": "http://koe-wiki.github.io/features/",
	"title": "Acoustic features",
	"tags": [],
	"description": "",
	"content": "Table of content \rFrequency domain features\r\r\r\r\rTime domain features\r\r\r\r\rPerceptual based features\r\r\r\r\r"
},
{
	"uri": "http://koe-wiki.github.io/user-manual/overview-workflow/",
	"title": "Overview of Koe workflow",
	"tags": [],
	"description": "",
	"content": "We designed the Koe workflow to be intuitive and flexible. Here is a suggested workflow:\n  Import raw recordings and divide into “songs” (vocalisation bouts), then segment songs into their constituent acoustic units.\n  You can extract acoustic features from units. These features are used to calculate unit similarity and expedite classification in two ways: through interactive ordination, and similarity indices.\n  Interactive ordination is a major time saver for classification. The user can encircle groups of points on the ordination to see spectrograms, hear playback, and bulk-label groups of units. Harnessing the interactive ordination in conjunction with human audio-visual perception, this technique offers a major advance in both speed and robustness over existing acoustic classification methods.\n  Units can also be viewed as an interactive unit table. A key feature of the unit table is the similarity index, which lets you sort by acoustic similarity. Because similar-sounding units are grouped together, units can easily be selected in bulk and classified.\n  A catalogue of class exemplars is generated automatically, displaying up to 10 randomly chosen exemplars for each class, which serves as a useful reference during classification.\n  Koe gives you full control of your databases, allowing you to add collaborators and set permission levels. This makes it straightforward to conduct a classification validation experiment: grant judges labelling access to your database, and once they have independently classified the units, compile their labels to examine concordance.\n  Once units have been classified, songs can be visualised as sequences of unit labels; you can filter by sequence to identify all instances of a specific song type, for example. You can also mine sequence structure in detail with association rule algorithms and network visualisations.\n  Export data from any program view as csv.\n  "
},
{
	"uri": "http://koe-wiki.github.io/features/frequency-domain/",
	"title": "Time domain features",
	"tags": [],
	"description": "",
	"content": "The time domain represents changes in the signal over time, or more precisely, the changes in air pressure when the sound reaches a microphone, which is measured by voltage value. Features in this category are necessarily extracted directly from the oscillogram without any transformation. Thus, they tend to have excellent time resolution and low computational cost.\nZero Crossing Rate (ZCR) Defined as the number of zero crossings within one second is an efficient way to approximate the dominant frequency\nTemporal Envelope Is the smoothed amplitude calculated by a moving window over the absolute value of the signal\u0026rsquo;s waveform. For signals that have relatively low and constant background noise, the temporal envelope provides a simple way to detect intervals of silence and thus could be used for audio segmentation.\nShort-time energy Is the mean square of the amplitude of the waveform over one frame\n$$p\\triangleq\\frac{\\sum_{i=t}^{t+d-1} {s_i}^2}{d}$$\nLoudness Is the root mean square of the amplitude of the waveform over one frame\n$$p\\triangleq\\sqrt{\\frac{\\sum_{i=t}^{t+d-1} {s_i}^2}{d}}$$\nTemporal Centroid Is the point in time where most of the signal energy is concentrated, calculated as the time average over the envelope of a signal in seconds\nLog Attack Time is the logarithm of time duration from the beginning of the sound to the point where the envelope reaches its first maximum. LAT characterises the attack of sound, which can be smooth or sudden.\n"
},
{
	"uri": "http://koe-wiki.github.io/user-manual/navigating-koe/",
	"title": "Navigating Koe",
	"tags": [],
	"description": "",
	"content": "\r\rIn Koe, on the left of the screen is a sidebar with program controls. At the top of the sidebar are User account controls for logging out / switching user; beneath that are controls specific to the active view. And beneath that is the workflow navigation pane with buttons to access different program views, labelled according to their function.\n"
},
{
	"uri": "http://koe-wiki.github.io/features/perceptual-features/",
	"title": "Perceptual based features",
	"tags": [],
	"description": "",
	"content": "Linear Predictive Cepstral Coefficients Is the Fourier transform of the log magnitude of the autoregressive power spectrum of the excitation source in a linear prediction model.\n"
},
{
	"uri": "http://koe-wiki.github.io/user-manual/user-and-db/",
	"title": "User and database control",
	"tags": [],
	"description": "",
	"content": "Create an account Go to koe.io.ac.nz and click on Register to register an account.\nChoose a username, input your name and email address for purposes of Koe support correspondence, and choose a password. (We will never share your information with anyone).\nCreate a new database Back to table of contents\nUnder Manage your database, click New database to create a new database.\nAdd collaborators to a database and set permission levels Back to table of contents\nYou can add collaborators at any stage.\n  Click on Manage your database.\n  Select the round checkbox of the database you want to add collaborators to.\n  Click Add collaborator and Type the Koe username or Koe account email address of your intended collaborator.\n  Once added, you can set their permission level by double-clicking the Permission cell next to their username.\n  From lowest to highest permission level: View, Annotate, Import data, Copy files, Add files, Modify segmentation, Delete files, Assign user. Each subsequent permission level extends the permissions of the previous level as per the table below:\n   Level Permissions     View User can view data   Annotate User can view and annotate data   Import data User can import, view and annotate data   Copy files User can copy files, import, view and annotate data   Add files User can add files, copy files, import, view and annotate data   Modify segmentation User can modify segmentation, add files, copy files, import, view and annotate data   Delete files User can delete files, modify segmentation, add files, copy files, import, view and annotate data   Assign user User can assign additional users, delete files, modify segmentation, add files, copy files, import, view and annotate data    Set database restore points Back to table of contents\nChanges are saved to the database as soon as they happen. If you want to be able to revert to a previous state you will want to save database restore points.\n  Click on Manage your database.\n  Select the round checkbox of the database you want to set a restore point for.\n  Click Quick save or Full save at the bottom of the window to create a restore point. Quick save saves label data associated with each unit. Full save saves both label data and segmentation start/end points.\n  Please note that restore points do not affect which songs are in the database or which units are segmented. For example, if you make a save and then delete songs, reverting will not restore the songs to the database. Similarly, if you add songs, reverting will not remove the added songs. In the same way, if you add/delete units, reverting will not remove/restore the segmentation. What reverting will do is restore the label data and (for a full save) the segmentation start/end points for currently existing units. If you want to preserve all aspects of a database at a certain point, like a traditional \u0026lsquo;Save As\u0026rsquo;, then copy everything to a new database, as described in Copy songs to another database below.\n"
},
{
	"uri": "http://koe-wiki.github.io/user-manual/songs-control/",
	"title": "Songs control",
	"tags": [],
	"description": "",
	"content": "Upload songs Click this link to download NZ bellbird songs to try out Upload songs feature and subsequent steps\nIf you have already-divided song files on your computer, you can upload these directly. On the navigation pane, click Upload songs and select up to 100 WAV files at once to upload.\nFor raw recordings that need to be divided into songs, see next step.\nUpload raw recordings and divide into songs Click this link to download raw (unsplit) recordings of bellbird song to try Upload \u0026amp; split raw recordings\nTo upload a raw recording and divide it into song selections, do the following:\nOn the navigation pane, click Upload \u0026amp; split raw recording\n  In the Upload raw recording dialogue box, Click Upload (WAV only)\n  Select the recording you want to upload\n  Click Open\n  After selecting a file to upload, an Upload raw recording dialogue appears with Track name and Record date fields. The track name is automatically filled in based on the wav filename. For example, Raw_Recording_001.wav will by default appear as Raw_Recording_001.\n Click in the Track name field to modify the track name, if you wish.\n  Click in the Record date field to modify the date. By default, the record date is set as the date of recording upload to Koe.\n  Click Submit track info.\n   For recordings with more than one channel, select the desired channel.\n  Play the recording with the playback controls, looking for songs to segment. To play from the beginning, click Play button.\n  You can also play from a specific timepoint by clicking that point, then clicking Play.\n  With the controls beneath the spectrogram, you can:\n Adjust spectrogram zoom.\n  Adjust spectrogram colour map.\n  Adjust playback speed.\n  Adjust spectrogram contrast.\n  To create a song selection simply drag over the spectrogram to create a selection box.  Click the selection box to play it. Adjust the selection box endpoints by holding Shift and dragging the box handles that appear.\nFor each selection you make, a row appears in the table beneath.\nFill in annotation columns as desired by double-clicking in those cells.   You can set an automatic naming scheme for segmented songs. Click the Naming pattern box to create a naming scheme with any combination of the following components: Track name, Year, Month, Day, Order. You can also add custom components to the scheme, such as text strings, if you wish. Click Rename all to apply the naming scheme to all existing song selections.\n  Once you’ve finished making song selections, click Save to upload the songs to the database. The raw recording will not be saved, only songs – so make sure you finish partitioning all songs in one go.\n  \rRecordings too big to upload? Use this tool to automatically split your wav files\n\rSome bioacoustics researchers work with looong recordings (e.g. passive acoustic monitoring). Very large files can be cumbersome. But don\u0026rsquo;t worry! Yukio Fukuzawa has heard your cries and has come galloping to our rescue with a simple tool for automatically splitting large wav files into smaller wav files. You specify how long you want the audio sections to be, and how many seconds of overlap between sections.\nTo run the tool you will need to install Python. After that it\u0026rsquo;s just a simple line of code that you type into your command prompt.\nThe tool and instructions are found here: https://github.com/fzyukio/split-songs\n"
},
{
	"uri": "http://koe-wiki.github.io/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://koe-wiki.github.io/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]